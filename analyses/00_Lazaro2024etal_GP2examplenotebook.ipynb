{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Example notebook for AMR ancestry - LÃ¡zaro 2024_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This notebook provides an example of searching for variants in chromosome 1 for the AMR ancestry. \n",
    "\n",
    "It covers the following steps:\n",
    "\n",
    "1. **Set up**\n",
    "2. **Installing packages**\n",
    "3. **Copy over data**\n",
    "4. **Create a covariate file with GP2 data**\n",
    "5. **Handle related individuals and other (non-PD) phenotypes**\n",
    "6. **Case/Control Frequencies**\n",
    "7. **Adjusted GLM model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use the os package to interact with the environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Bring in Pandas for Dataframe functionality\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "# Bring some visualization functionality \n",
    "import seaborn as sns  \n",
    "\n",
    "# numpy for basics\n",
    "import numpy as np\n",
    "\n",
    "# Use StringIO for working with file contents\n",
    "from io import StringIO\n",
    "\n",
    "# Enable IPython to display matplotlib graphs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable interaction with the FireCloud API\n",
    "from firecloud import api as fapi\n",
    "\n",
    "# Import the iPython HTML rendering for displaying links to Google Cloud Console\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Import urllib modules for building URLs to Google Cloud Console\n",
    "import urllib.parse\n",
    "\n",
    "# BigQuery for querying data\n",
    "from google.cloud import bigquery\n",
    "\n",
    "#Import Sys\n",
    "import sys as sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Python libraries and defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility routine for printing a shell command before executing it\n",
    "def shell_do(command):\n",
    "    print(f'Executing: {command}', file=sys.stderr)\n",
    "    !$command\n",
    "    \n",
    "def shell_return(command):\n",
    "    print(f'Executing: {command}', file=sys.stderr)\n",
    "    output = !$command\n",
    "    return '\\n'.join(output)\n",
    "\n",
    "# Utility routine for printing a query before executing it\n",
    "def bq_query(query):\n",
    "    print(f'Executing: {query}', file=sys.stderr)\n",
    "    return pd.read_gbq(query, project_id=BILLING_PROJECT_ID, dialect='standard')\n",
    "\n",
    "# Utility routine for display a message and a link\n",
    "def display_html_link(description, link_text, url):\n",
    "    html = f'''\n",
    "    <p>\n",
    "    </p>\n",
    "    <p>\n",
    "    {description}\n",
    "    <a target=_blank href=\"{url}\">{link_text}</a>.\n",
    "    </p>\n",
    "    '''\n",
    "\n",
    "    display(HTML(html))\n",
    "\n",
    "# Utility routines for reading files from Google Cloud Storage\n",
    "def gcs_read_file(path):\n",
    "    \"\"\"Return the contents of a file in GCS\"\"\"\n",
    "    contents = !gsutil -u {BILLING_PROJECT_ID} cat {path}\n",
    "    return '\\n'.join(contents)\n",
    "    \n",
    "def gcs_read_csv(path, sep=None):\n",
    "    \"\"\"Return a DataFrame from the contents of a delimited file in GCS\"\"\"\n",
    "    return pd.read_csv(StringIO(gcs_read_file(path)), sep=sep, engine='python')\n",
    "\n",
    "# Utility routine for displaying a message and link to Cloud Console\n",
    "def link_to_cloud_console_gcs(description, link_text, gcs_path):\n",
    "    url = '{}?{}'.format(\n",
    "        os.path.join('https://console.cloud.google.com/storage/browser',\n",
    "                     gcs_path.replace(\"gs://\",\"\")),\n",
    "        urllib.parse.urlencode({'userProject': BILLING_PROJECT_ID}))\n",
    "\n",
    "    display_html_link(description, link_text, url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up billing project and data path variables\n",
    "BILLING_PROJECT_ID = os.environ['GOOGLE_PROJECT']\n",
    "WORKSPACE_NAMESPACE = os.environ['WORKSPACE_NAMESPACE']\n",
    "WORKSPACE_NAME = os.environ['WORKSPACE_NAME']\n",
    "WORKSPACE_BUCKET = os.environ['WORKSPACE_BUCKET']\n",
    "WORKSPACE_ATTRIBUTES = fapi.get_workspace(WORKSPACE_NAMESPACE, WORKSPACE_NAME).json().get('workspace',{}).get('attributes',{})\n",
    "\n",
    "## Print the information to check we are in the proper release and billing \n",
    "## This will be different for you, the user, depending on the billing project your workspace is on\n",
    "print('Billing and Workspace')\n",
    "print(f'Workspace Name @ `WORKSPACE_NAME`: {WORKSPACE_NAME}')\n",
    "print(f'Billing Project @ `BILLING_PROJECT_ID`: {BILLING_PROJECT_ID}')\n",
    "print(f'Workspace Bucket, where you can upload and download data @ `WORKSPACE_BUCKET`: {WORKSPACE_BUCKET}')\n",
    "print('')\n",
    "\n",
    "## AMP-PD v3.0\n",
    "## Explicitly define release v3.0 path \n",
    "AMP_RELEASE_PATH = 'gs://amp-pd-data/releases/release/path'  ##  Enter valid release path\n",
    "AMP_CLINICAL_RELEASE_PATH = f'{AMP_RELEASE_PATH}/clinical'\n",
    "AMP_RELEASE_GATK_PATH = os.path.join(AMP_RELEASE_PATH, 'gatk')\n",
    "AMP_WGS_RELEASE_PATH = 'gs://amp-pd-genomics/releases/release/path'   ##  Enter valid release path\n",
    "AMP_WGS_RELEASE_PLINK_PATH = os.path.join(AMP_WGS_RELEASE_PATH, 'plink')\n",
    "AMP_WGS_RELEASE_PLINK_PFILES = os.path.join(AMP_WGS_RELEASE_PLINK_PATH, 'pfiles')\n",
    "\n",
    "print('AMP-PD v3.0')\n",
    "print(f'Path to AMP-PD v3.0 Clinical Data: {AMP_CLINICAL_RELEASE_PATH}')\n",
    "print(f'Path to AMP-PD v3.0 WGS Data: {AMP_WGS_RELEASE_PLINK_PATH}')\n",
    "print(f'Path to AMP-PD v3.0 WGS Data: {AMP_WGS_RELEASE_PLINK_PFILES}')\n",
    "print('')\n",
    "\n",
    "## GP2 v7.0\n",
    "## Explicitly define release v7.0 path \n",
    "GP2_RELEASE_PATH = '/GP2/release/path' ##  Enter valid GP2 Release path\n",
    "GP2_CLINICAL_RELEASE_PATH = f'{GP2_RELEASE_PATH}/clinical_data'\n",
    "GP2_RAW_GENO_PATH = f'{GP2_RELEASE_PATH}/raw_genotypes'\n",
    "GP2_IMPUTED_GENO_PATH = f'{GP2_RELEASE_PATH}/imputed_genotypes'\n",
    "GP2_META_RELEASE_PATH = f'{GP2_RELEASE_PATH}/meta_data'\n",
    "GP2_SUMSTAT_RELEASE_PATH = f'{GP2_RELEASE_PATH}/summary_statistics'\n",
    "\n",
    "print('GP2 v7.0')\n",
    "print(f'Path to GP2 v7.0 Clinical Data @ `GP2_CLINICAL_RELEASE_PATH`: {GP2_CLINICAL_RELEASE_PATH}')\n",
    "print(f'Path to GP2 v7.0 Metadata @ `GP2_META_RELEASE_PATH`: {GP2_META_RELEASE_PATH}')\n",
    "print(f'Path to GP2 v7.0 Raw Genotype Data @ `GP2_RAW_GENO_PATH`: {GP2_RAW_GENO_PATH}')\n",
    "print(f'Path to GP2 v7.0 Imputed Genotype Data @ `GP2_IMPUTED_GENO_PATH`: {GP2_IMPUTED_GENO_PATH}')\n",
    "print(f'Path to GP2 v7.0 summary statistics: {GP2_SUMSTAT_RELEASE_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ancestry = 'AMR'\n",
    "WORK_DIR = f'{ancestry}'\n",
    "\n",
    "! mkdir {WORK_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p ~/tools\n",
    "cd ~/tools\n",
    "\n",
    "if test -e /home/jupyter/tools/plink; then\n",
    "echo \"Plink1.9 is already installed in /home/jupyter/tools/\"\n",
    "\n",
    "else\n",
    "echo -e \"Downloading plink \\n    -------\"\n",
    "wget -N http://s3.amazonaws.com/plink1-assets/plink_linux_x86_64_20190304.zip \n",
    "unzip -o plink_linux_x86_64_20190304.zip\n",
    "echo -e \"\\n plink downloaded and unzipped in /home/jupyter/tools \\n \"\n",
    "\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p ~/tools\n",
    "cd ~/tools\n",
    "\n",
    "if test -e /home/jupyter/tools/plink2; then\n",
    "echo \"Plink2 is already installed in /home/jupyter/tools/\"\n",
    "\n",
    "else\n",
    "echo -e \"Downloading plink2 \\n    -------\"\n",
    "wget -N https://s3.amazonaws.com/plink2-assets/alpha5/plink2_linux_amd_avx2_20240625.zip\n",
    "unzip -o plink2_linux_amd_avx2_20240625.zip\n",
    "echo -e \"\\n plink2 downloaded and unzipped in /home/jupyter/tools \\n \"\n",
    "\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy Over Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  Imputed genotype GP2 Tier 2 data\n",
    "## In this case, we will use tyhe chromosome 1 as an example \n",
    "\n",
    "\n",
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp -r {GP2_IMPUTED_GENO_PATH}/AMR/chr1_AMR_release7* {WORK_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clinical data \n",
    "\n",
    "## master key\n",
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp {GP2_CLINICAL_RELEASE_PATH}/master_key_release7_final.csv {WORK_DIR}')\n",
    "\n",
    "## related file \n",
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp {GP2_META_RELEASE_PATH}/related_samples/{ancestry}_release7.related {WORK_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## PCs\n",
    "shell_do(f'gsutil -u {BILLING_PROJECT_ID} -m cp {GP2_RAW_GENO_PATH}/{ancestry}/{ancestry}_release7.eigenvec {WORK_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Check files\n",
    "! ls {WORK_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a covariate file with GP2 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariate file is creating by putting together clinical, PC and genetic files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clinical master key\n",
    "clin = pd.read_csv(f'{WORK_DIR}/master_key_release7_final.csv')\n",
    "clin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genetic data\n",
    "gen = pd.read_csv(f'{WORK_DIR}/chr1_AMR_release7.psam', sep='\\t')\n",
    "gen.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = pd.read_csv(f'{WORK_DIR}/AMR_release7.eigenvec', sep='\\t')\n",
    "pcs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen2 = pd.merge(gen, clin, left_on='#IID', right_on='GP2sampleID')\n",
    "gen2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen3 = pd.merge(gen2, pcs, left_on='#IID', right_on='IID')\n",
    "gen3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Subsetting to keep only a few columns \n",
    "plink_clin = gen3[['#IID', 'SEX', 'PHENO1', 'age_at_sample_collection', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5']]\n",
    "plink_clin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename age_at_sample_collection  \n",
    "plink_clin = plink_clin.rename(columns={'age_at_sample_collection': 'AGE'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plink_clin.to_csv(f'{WORK_DIR}/{ancestry}covars.txt', sep='\\t', index=False, na_rep='-9',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covars = pd.read_csv(f'{WORK_DIR}/{ancestry}covars.txt', sep='\\t')\n",
    "covars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle related individuals and other (non-PD) phenotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can load the related file \n",
    "related_df = pd.read_csv(f'{WORK_DIR}/{ancestry}_release7.related')\n",
    "print(related_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a list of individuals to remove from the dataframe\n",
    "! cut -d, -f2 {WORK_DIR}/AMR_release7.related > {WORK_DIR}/related_ids.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we remove them from the genetic file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/home/jupyter/tools/plink2 \\\n",
    "--pfile {WORK_DIR}/chr1_AMR_release7 \\\n",
    "--remove {WORK_DIR}/related_ids.txt \\\n",
    "--make-pgen \\\n",
    "--out {WORK_DIR}/chr1_AMR_release7_nonrelated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-PD phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = f'{ancestry}'\n",
    "\n",
    "! /home/jupyter/tools/plink2 \\\n",
    "--pfile {WORK_DIR}/chr1_AMR_release7_nonrelated  \\\n",
    "--prune \\\n",
    "--make-pgen \\\n",
    "--out {WORK_DIR}/chr1_AMR_release7_nonrelated_pdc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case/Control Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Glossary\n",
    "\n",
    "- CHR\tChromosome code\n",
    "- SNP\tVariant identifier\n",
    "- A1\tAllele 1 (usually minor)\n",
    "- A2\tAllele 2 (usually major)\n",
    "- MAF\tAllele 1 frequency in all subjects\n",
    "- F_A/MAF_A\tAllele 1 frequency in cases\n",
    "- F_U/MAF_U\tAllele 1 frequency in controls\n",
    "- NCHROBS_A\tNumber of case allele observations\n",
    "- NCHROBS_U\tNumber of control allele observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the region of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you can create a file with the format CHR BP_START BP_END of the SNPs you are interested in studying. As an example, we create in the next chunk a file \"range_chr1.txt\" with 2 SNPs in chromosome 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNP_coordinates = [\n",
    "    \"1 226728377 226728377\",\n",
    "    \"1 11796321 11796321\"\n",
    "]\n",
    "\n",
    "# Write to a text file\n",
    "with open(\"AMR/range_chr1.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(SNP_coordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the regions and create plink and plink2 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {WORK_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = f'{ancestry}'\n",
    "\n",
    "! /home/jupyter/tools/plink2 \\\n",
    "--pfile {WORK_DIR}/chr1_AMR_release7_nonrelated_pdc \\\n",
    "--extract range {WORK_DIR}/range_chr1.txt \\\n",
    "--make-pgen \\\n",
    "--out {WORK_DIR}/snpextracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = f'{ancestry}'\n",
    "\n",
    "! /home/jupyter/tools/plink2 \\\n",
    "--pfile {WORK_DIR}/snpextracted \\\n",
    "--make-bed \\\n",
    "--out {WORK_DIR}/snpextracted_plink1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate frequencies using Plink 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = f'{ancestry}'\n",
    "\n",
    "! /home/jupyter/tools/plink \\\n",
    "--bfile {WORK_DIR}/snpextracted_plink1 \\\n",
    "--assoc \\\n",
    "--ci 0.95 \\\n",
    "--out {WORK_DIR}/AMR_assoc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat {WORK_DIR}/AMR_assoc.assoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate glm (adjusted model) using Plink 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = f'{ancestry}'\n",
    "\n",
    "! /home/jupyter/tools/plink2 \\\n",
    "--pfile {WORK_DIR}/snpextracted \\\n",
    "--glm hide-covar firth-fallback pheno-ids \\\n",
    "--covar-name AGE,SEX,PC1,PC2,PC3,PC4,PC5 \\\n",
    "--pheno-name PHENO1 \\\n",
    "--pheno {WORK_DIR}/{ancestry}covars.txt \\\n",
    "--ci 0.95 \\\n",
    "--covar-variance-standardize \\\n",
    "--covar {WORK_DIR}/{ancestry}covars.txt \\\n",
    "--out {WORK_DIR}/AMR_glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat {WORK_DIR}/AMR_glm.PHENO1.glm.logistic.hybrid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "218.99px",
    "width": "434.969px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "357px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
